{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "#polarities = {1:'Very Negative',2:'Negative', 3:'Neutral', 4:'Positive', 5:'Very Positive'}\n",
    "\n",
    "\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    "\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "\n",
    "\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    '''\n",
    "    stemmer = PorterStemmer()\n",
    "    emoji_pattern = re.compile(\"[\"  \n",
    "         u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    #tweet = re.sub(r'@','',tweet)\n",
    "    \n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "    #remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    \n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation and word not in emoticons):  # remove punctuation and emoticons\n",
    "            tweets_clean.append(word)\n",
    "        \n",
    "        if word in emoticons_happy:\n",
    "            tweets_clean.append('Happy')\n",
    "        elif word in emoticons_sad:\n",
    "            tweets_clean.append('Sad')\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "            #stem_word = stemmer.stem(word)  # stemming word\n",
    "            #tweets_clean.append(stem_word)\n",
    "    \n",
    "    tweet = ' '.join(tweets_clean)\n",
    "\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def test_lookup(func):\n",
    "    freqs = {('sad', 0): 4,\n",
    "             ('happy', 1): 12,\n",
    "             ('oppressed', 0): 7}\n",
    "    word = 'happy'\n",
    "    label = 1\n",
    "    if func(freqs, word, label) == 12:\n",
    "        return 'SUCCESS!!'\n",
    "    return 'Failed Sanity Check!'\n",
    "\n",
    "\n",
    "def lookup(freqs, word, label):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        word: the word to look up\n",
    "        label: the label corresponding to the word\n",
    "    Output:\n",
    "        n: the number of times the word with its corresponding label appears.\n",
    "    '''\n",
    "    n = 0  # freqs.get((word, label), 0)\n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n\n",
    "\n",
    "\n",
    "\n",
    "def normalize_sentiment(val):\n",
    "    \n",
    "    senMin = -1\n",
    "    senMax = 1\n",
    "    neutral = 0\n",
    "    polMin = 1\n",
    "    polMax =5\n",
    "\n",
    "\n",
    "    newval = ((val -senMin)/(senMax-senMin))*(polMax-polMin)+polMin\n",
    "        \n",
    "    return round(newval)\n",
    "\n",
    "def get_opinion(val):\n",
    "    if val < 0:\n",
    "        \n",
    "        senti= 'Negative' if round(val)==0 else 'Very Negative' \n",
    "\n",
    "    elif val > 0:\n",
    "\n",
    "        senti= 'Positive' if round(val)==0 else 'Very Positive'\n",
    "\n",
    "    else:\n",
    "        senti= 'Neutral'\n",
    "    \n",
    "    return senti\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey buddy listen work Sad check work\n",
      "Negative\n",
      "Sentiment(polarity=-0.5, subjectivity=1.0)\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Hey Buddy @kiran listen. Your work is :@ . Check his work at https://kiran\"\n",
    "print(process_tweet(tweet))\n",
    "print(get_opinion(TextBlob(process_tweet(tweet)).sentiment.polarity))\n",
    "print(TextBlob(process_tweet(tweet)).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aim is to get tweets based on hashtags which has covid-19 apps, security, covid19.\n",
    "#Data Extraction first\n",
    "#Reference : https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token_key='1097367016456011776-bKEHl6bEgWc7gnd3cIqu3KlYsWgoi4'\n",
    "access_token_secret='k8CVegeF8hzHJJQDTWEqQ1rzUVYn228TK5eMaO8Pan2M9'\n",
    "consumer_key='CdNDp6wqPDmgUAQqCkikjNmTG'\n",
    "consumer_secret='jTSjfniCLUEdmLplHGEniFVz0L2Ha7yfrWhxUvOGBWuN51OOyQ'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "\n",
    "auth.set_access_token(access_token_key,access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "twtr = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#covid_keys = '#covid19apps OR #covidtracker OR #covidappsecurity OR #COVID19APPS OR #covid19tracker OR #covidappssecurity OR #Covid19AppSecurity OR #Corona19TrackerApps OR #Corona19Apps OR #Corona19AppsPrivacy OR #CoronaAppsSurveillance OR #Covid19Tracker OR #Covid19Surveillance -filter:retweets' #202,30,0,24\n",
    "covid_keys = '#Covid19Tracker'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "new_entry=[]\n",
    "for page in tweepy.Cursor(twtr.search,q=covid_keys,include_rts=False,lang='en').pages(100):\n",
    "    for status in page:\n",
    "        #print(\"Page: \",counter)\n",
    "        status = status._json\n",
    "        #print(status['text'])\n",
    "        original_twt = status['text']\n",
    "        twt=process_tweet(original_twt)\n",
    "        #opinion = polarities[normalize_sentiment(TextBlob(twt).sentiment.polarity)]\n",
    "        sentiment = TextBlob(twt).sentiment\n",
    "        polarity = sentiment.polarity\n",
    "        subjectivity = sentiment.subjectivity\n",
    "        opinion = get_opinion(polarity)\n",
    "        timestamp = status['created_at']\n",
    "        try:\n",
    "            location = status['user']['location']\n",
    "        except TypeError:\n",
    "            location = ''\n",
    "        \n",
    "        \n",
    "        counter+=1\n",
    "        \n",
    "        new_entry.append([counter,original_twt,location,timestamp,polarity,subjectivity,opinion])\n",
    "        \n",
    "        \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five categories: \n",
    "#{1 to be strongly negative, 2 to be negative, 3 to be neutral, 4 to be positive, and 5 to be strongly positive}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1=5\n",
    "# -1=1\n",
    "\n",
    "\n",
    "#normalization formula from:https://stats.stackexchange.com/questions/281162/scale-a-number-between-a-range\n",
    "\n",
    "    #   or\n",
    "#   newvalue= (max'-min')/(max-min)*(value-min)+min'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_entry, columns=['id','Tweet','location','time','polarity','subjectivity','opinion'])\n",
    "#july_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Negative', 'Neutral', 'Positive'], dtype=object),\n",
       " array([13, 61,  9], dtype=int64))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(df['opinion'],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets_data_onlyCTracker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Join our WEBINAR Wed July 22 9:00 EDT as we di...</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Mon Jul 20 21:03:00 +0000 2020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @WFIChampions: Join our WEBINAR Wed July 22...</td>\n",
       "      <td>Vienna, Austria</td>\n",
       "      <td>Mon Jul 20 21:02:44 +0000 2020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @VertoAnalytics: The COVID-19 crisis has af...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Mon Jul 20 20:17:57 +0000 2020</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              Tweet         location  \\\n",
       "0   1  Join our WEBINAR Wed July 22 9:00 EDT as we di...   Washington, DC   \n",
       "1   2  RT @WFIChampions: Join our WEBINAR Wed July 22...  Vienna, Austria   \n",
       "2   3  RT @VertoAnalytics: The COVID-19 crisis has af...    New York City   \n",
       "\n",
       "                             time  polarity  subjectivity   opinion  \n",
       "0  Mon Jul 20 21:03:00 +0000 2020  0.000000           0.0   Neutral  \n",
       "1  Mon Jul 20 21:02:44 +0000 2020  0.000000           0.0   Neutral  \n",
       "2  Mon Jul 20 20:17:57 +0000 2020  0.333333           1.0  Positive  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
